{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the big influencer dump csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Files can be found in polarbear:/meltwater/influencer-data/\n",
    "influencer_dump_file = \"influencer_updates.csv\"\n",
    "influencer_dump_dataframe = pd.read_csv(influencer_dump_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the file list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_name_list = []\n",
    "num_file = 15\n",
    "for i in range (0, num_file) :\n",
    "    fn = str(i) + '_doc_stats_staging.csv'\n",
    "    file_name_list.append(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframe_all = pd.DataFrame(columns=[\"UUID\", \"doc_count_staging\"])\n",
    "\n",
    "for file_name in file_name_list:\n",
    "    dataframe_temp = pd.read_csv(file_name_list[0], header = None)\n",
    "    dataframe_temp.columns = [\"UUID\", \"doc_count_staging\"]\n",
    "\n",
    "    dataframe_all = dataframe_all.append(dataframe_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_count_staging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>114.099600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>838.753668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20274.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       doc_count_staging\n",
       "count      150000.000000\n",
       "mean          114.099600\n",
       "std           838.753668\n",
       "min             0.000000\n",
       "25%             0.000000\n",
       "50%             0.000000\n",
       "75%             4.000000\n",
       "max         20274.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_all.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting total zero and non-zero doc_count_staging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6227\n",
      "% of zero doc:  4.1513333333333335\n"
     ]
    }
   ],
   "source": [
    "zero_doc = len(set(dataframe_all.groupby('doc_count_staging').groups[0.0]))\n",
    "print (zero_doc)\n",
    "#print (\"% of zero doc: \", 100.0 * zero_doc / len(setdataframe_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1852\n"
     ]
    }
   ],
   "source": [
    "more_than_10_doc = 0\n",
    "groupby_doc_count_staging = dataframe_all.groupby('doc_count_staging').groups\n",
    "for key in groupby_doc_count_staging.keys() :\n",
    "    if key > 10.0:\n",
    "        more_than_10_doc = more_than_10_doc + len(set(groupby_doc_count_staging[key]))\n",
    "print (more_than_10_doc)\n",
    "#print (\"% of more than 10 doc: \", 100.0 * more_than_10_doc / len(dataframe_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting influencer ids having more than n document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_influencer_id_n_doc(df_all, num_doc):\n",
    "    influencer_id = []\n",
    "    groupby_doc_count_staging = df_all.groupby('doc_count_staging').groups\n",
    "    for key in groupby_doc_count_staging.keys() :\n",
    "        if key > num_doc:\n",
    "            influencer_id.extend(groupby_doc_count_staging[key])\n",
    "    return set(influencer_id)\n",
    "\n",
    "influencer_id = get_influencer_id_n_doc(dataframe_all, 20.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cropped_df = dataframe_all.ix[influencer_id]\n",
    "cropped_df_grouped = cropped_df.groupby(level=0)\n",
    "cropped_df = cropped_df_grouped.last()\n",
    "cropped_df_sorted = cropped_df.sort_values(by=['doc_count_staging'], ascending=[True])\n",
    "cropped_df_sorted.to_csv(\"influencer_id_more_than_20_doc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.csv                                                    32.csv\r\n",
      "0_doc_stats_staging.csv                                  33.csv\r\n",
      "1.csv                                                    34.csv\r\n",
      "10.csv                                                   3_doc_stats_staging.csv\r\n",
      "10_doc_stats_staging.csv                                 4.csv\r\n",
      "11.csv                                                   4_doc_stats_staging.csv\r\n",
      "11_doc_stats_staging.csv                                 5.csv\r\n",
      "12.csv                                                   5_doc_stats_staging.csv\r\n",
      "12_doc_stats_staging.csv                                 6.csv\r\n",
      "13.csv                                                   6_doc_stats_staging.csv\r\n",
      "13_doc_stats_staging.csv                                 7.csv\r\n",
      "14.csv                                                   7_doc_stats_staging.csv\r\n",
      "14_doc_stats_staging.csv                                 8.csv\r\n",
      "15.csv                                                   8_doc_stats_staging.csv\r\n",
      "16.csv                                                   9.csv\r\n",
      "17.csv                                                   9_doc_stats_staging.csv\r\n",
      "18.csv                                                   Category_similarity_child_beat.ipynb\r\n",
      "19.csv                                                   Experiment_on_influencer-data.ipynb\r\n",
      "1_doc_stats_staging.csv                                  \u001b[31mHow_many_documents_are_in_FH_for_each_influencer-.ipynb\u001b[m\u001b[m*\r\n",
      "2.csv                                                    Plotting_doc_stats.ipynb\r\n",
      "20.csv                                                   README\r\n",
      "21.csv                                                   contact_less_than_10_doc_stats.csv\r\n",
      "22.csv                                                   contact_more_than_10_doc_stats.csv\r\n",
      "23.csv                                                   contact_w_o_articles.csv\r\n",
      "24.csv                                                   contact_w_o_doc_stats.csv\r\n",
      "25.csv                                                   contacts_10_+articles.csv\r\n",
      "26.csv                                                   contacts_10_+articles_doc_stats.csv\r\n",
      "27.csv                                                   contacts_less_10_article.csv\r\n",
      "28.csv                                                   contacts_w_o_doc_stats.csv\r\n",
      "29.csv                                                   influencer_data_preparation.ipynb\r\n",
      "2_doc_stats_staging.csv                                  influencer_doc_stats_from_csv.ipynb\r\n",
      "3.csv                                                    influencer_id_more_than_20_doc.csv\r\n",
      "30.csv                                                   influencer_updates.csv\r\n",
      "31.csv                                                   template_query.json\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
